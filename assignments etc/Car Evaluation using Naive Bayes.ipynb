{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import sys # why? some tutorial somewhere said so...\n",
    "\n",
    "df = pandas.read_csv('car_data.csv')\n",
    "\n",
    "BuyingD = {\"vhigh\":0, \"high\":1, \"med\":2, \"low\":3}\n",
    "MaintD = BuyingD\n",
    "DoorsD = {\"2\":0, \"3\":1, \"4\":2, \"5more\":3}\n",
    "PersonsD = {\"2\":0, \"4\":1, \"more\":2}\n",
    "Lug_BootD = {\"small\":0, \"med\":1, \"big\":2}\n",
    "SafetyD = {\"low\":0, \"med\":1, \"high\":2}\n",
    "ClassD = {\"unacc\":0, \"acc\":1, \"good\":2, \"vgood\":3}\n",
    "\n",
    "pb = numpy.zeros((4,4)) # first index is attribute option, second index is class\n",
    "pm = numpy.zeros((4,4)) # since no. of classes is always 4, 2nd index is always 4\n",
    "pd = numpy.zeros((4,4))\n",
    "pp = numpy.zeros((3,4))\n",
    "pl = numpy.zeros((3,4))\n",
    "ps = numpy.zeros((3,4))\n",
    "PClass = numpy.zeros(4)\n",
    "\n",
    "# Of course, this whole ordeal would be easier if, instead of 6 2-D arrays, we used an array of 6 2-D arrays.\n",
    "# However, these are not of same size (or is the proper numpy terminology 'shape'?) so that could be a problem.\n",
    "\n",
    "for u in zip(df['buying'],df['class']):\n",
    "    pb[BuyingD[u[0]],ClassD[u[1]]] += 1\n",
    "for u in zip(df['maint'],df['class']):\n",
    "    pm[MaintD[u[0]],ClassD[u[1]]] += 1\n",
    "for u in zip(df['doors'],df['class']):\n",
    "    pd[DoorsD[u[0]],ClassD[u[1]]] += 1\n",
    "for u in zip(df['persons'],df['class']):\n",
    "    pp[PersonsD[u[0]],ClassD[u[1]]] += 1\n",
    "for u in zip(df['lug_boot'],df['class']):\n",
    "    pl[Lug_BootD[u[0]],ClassD[u[1]]] += 1\n",
    "for u in zip(df['safety'],df['class']):\n",
    "    ps[SafetyD[u[0]],ClassD[u[1]]] += 1\n",
    "for u in df['class']:\n",
    "    PClass[ClassD[u]] += 1\n",
    "\n",
    "# print(pb,\";\\n\",pm,\";\\n\",pd,\";\\n\",pp,\";\\n\",pl,\";\\n\",ps) # test line\n",
    "# population matrices are filled, now to normalize them into probability matrices.\n",
    "pb = pb/numpy.sum(pb,axis=1,keepdims=True)\n",
    "pm = pm/numpy.sum(pm,axis=1,keepdims=True)\n",
    "pd = pd/numpy.sum(pd,axis=1,keepdims=True)\n",
    "pp = pp/numpy.sum(pp,axis=1,keepdims=True)\n",
    "pl = pl/numpy.sum(pl,axis=1,keepdims=True)\n",
    "ps = ps/numpy.sum(ps,axis=1,keepdims=True)\n",
    "PClass = PClass/1728\n",
    "\n",
    "def ClassDetermination(buying=-1,maint=-1,doors=-1,persons=-1,lug_boot=-1,safety=-1):\n",
    "    \"\"\"Accepts up to 6 integers. Parameters and their accepted ranges (inclusive) are:\n",
    "        buying:   [0,3]\n",
    "        maint:    [0,3]\n",
    "        doors:    [0,3]\n",
    "        persons:  [0,2]\n",
    "        lug_boot: [0,2]\n",
    "        safety:   [0,2]\n",
    "    If a negative number is entered, it has no effect. If a positive number out of bounds is entered, it throws an\n",
    "    out-of-bounds error. Parameters can be omitted, at which point forcing you to specify what field you're entering.\"\"\"\n",
    "    \n",
    "    # Attributes are given via numbers, not strings.\n",
    "    \n",
    "    # SEE CELL \"4\" FOR:\n",
    "    # FIRST COMMENT OF THE WORK: DETAILING OUR METHODOLOGY AND REASONING\n",
    "    \n",
    "    # If attribute is not supplied, i.e. we have default value, then it's not considered in calculations.\n",
    "    # Also of note: *, when applied to matrices, is NOT matrix/inner/dot multiplication, instead is term-by-term,\n",
    "    #    [Turns out, this is because we're currently dealing with NOT numpy matrices BUT numpy arrays.\n",
    "    #     If they were matrices, * WOULD be matrix multiplication.]\n",
    "    # hence the following lines:\n",
    "    Mult = numpy.ones(4)\n",
    "    if buying >= 0:\n",
    "        Mult = Mult * pb[buying]\n",
    "    if maint >= 0:\n",
    "        Mult = Mult * pm[maint]\n",
    "    if doors >= 0:\n",
    "        Mult = Mult * pd[doors]\n",
    "    if persons >= 0:\n",
    "        Mult = Mult * pp[persons]\n",
    "    if lug_boot >= 0:\n",
    "        Mult = Mult * pl[lug_boot]\n",
    "    if safety >= 0:\n",
    "        Mult = Mult * pb[safety]\n",
    "        \n",
    "    # And now, finally:\n",
    "    p = Mult*PClass\n",
    "    return p/numpy.sum(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Moved to its own notebook. Also left here for further confusion.\n",
    "import numpy\n",
    "import pandas\n",
    "import math\n",
    "\n",
    "IrisData = pandas.read_csv('bezdekIris.csv', header=-1)\n",
    "# IrisDict = {\"Iris-setosa\":0, \"Iris-versicolor\":1, \"Iris-virginica\":2} # Do we even need this? (Answered 'no', commented out)\n",
    "# all columns except last one are floats\n",
    "\n",
    "# Attributes:\n",
    "#    1. sepal length in cm\n",
    "#    2. sepal width  in cm\n",
    "#    3. petal length in cm\n",
    "#    4. petal width  in cm\n",
    "#    5. class: \n",
    "\n",
    "# Summary Statistics: # Not completely relevant to our study, but still nice to have around.\n",
    "#                  Min  Max   Mean    SD   Class Correlation\n",
    "#    sepal length: 4.3  7.9   5.84  0.83    0.7826   \n",
    "#    sepal width:  2.0  4.4   3.05  0.43   -0.4194\n",
    "#    petal length: 1.0  6.9   3.76  1.76    0.9490  (high!)\n",
    "#    petal width:  0.1  2.5   1.20  0.76    0.9565  (high!)\n",
    "\n",
    "# Some high level plays; thanks to stackoverflow\n",
    "# @ https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas\n",
    "IrisData = IrisData.set_index([4])\n",
    "SeD = IrisData.loc['Iris-setosa']\n",
    "VeD = IrisData.loc['Iris-versicolor']\n",
    "ViD = IrisData.loc['Iris-virginica']\n",
    "\n",
    "del IrisData\n",
    "\n",
    "MeanByClass = numpy.array([SeD.mean().as_matrix(), VeD.mean().as_matrix(), ViD.mean().as_matrix()])\n",
    "StdByClass = numpy.array([SeD.std().as_matrix(), VeD.std().as_matrix(), ViD.std().as_matrix()])\n",
    "StatsByClass = numpy.dstack((MeanByClass,StdByClass))\n",
    "    # once again, thanks to stackoverflow\n",
    "    # @ https://stackoverflow.com/questions/17960441/in-numpy-how-to-zip-two-2-d-arrays\n",
    "    # here, indexing is as follows: [class, attribute, mean/std]\n",
    "    # so [1,2,0] is \"2nd class: Ve, 3rd att: pl, 1st opt: mean\"\n",
    "    \n",
    "    # At this point, we can delete all data frames (SeD, VeD, ViD) and single stat by classes.\n",
    "    # StatsByClass is, for all intents and purposes, all we need.\n",
    "\n",
    "def NormalProb(point, mean=0., std=1., interval=0.01):\n",
    "    # For details see:\n",
    "    # http://mathworld.wolfram.com/NormalDistribution.html\n",
    "    # http://mathworld.wolfram.com/Erf.html\n",
    "    # https://docs.python.org/dev/library/math.html#math.erf\n",
    "    xlower = ((point-mean)-interval*0.5)/std\n",
    "    xupper = ((point-mean)+interval*0.5)/std\n",
    "    return (math.erf(xupper/math.sqrt(2.))-math.erf(xlower/math.sqrt(2.)))/2.\n",
    "    \n",
    "def FlowerDetermination(sl=0,sw=0,pl=0,pw=0):\n",
    "    \"\"\"Accepts up to 4 floats, returns probability of each class being in its range.\n",
    "    Since we have a continuous probability distribution function, but user is\n",
    "    entering single values, results are taken in an interval of length 0.1\n",
    "    around point x0, i.e. in x0+-0.05.\n",
    "    \n",
    "    Though the data set is finite, and has a maximum and minimum, we are making a\n",
    "    normalized approximation, therefore any number is (theoritically) possible. However,\n",
    "    since all variables correspond to physical measurements (lengths and widths) any\n",
    "    non-positive entries will be omitted.\n",
    "    \n",
    "    Following is a listing of our parameters and their real-world correspondants:\n",
    "        sl: Sepal Length\n",
    "        sw: Sepal Width\n",
    "        pl: Petal Length\n",
    "        pw: Petal Width\"\"\"\n",
    "    \n",
    "    # Once again, we have 4 numbers (sl, sw, pl, pw) and we will return an array of 3 numbers:\n",
    "    # p1 = p(1|(sl+-0.05, sw+-0.05, pl+-0.05, pw+-0.05))\n",
    "    #    = p((sl+-0.05, sw+-0.05, pl+-0.05, pw+-0.05)|1)*p(1)\n",
    "    #    = p(sl+-0.05|1)*p(sw+-0.05|1)*p(pl+-0.05|1)*p(pw+-0.05|1)*p(1)\n",
    "    #     # Here, p(Class)=1/3 for all Class, so can be omitted.\n",
    "    # To find, let's say, p(sl+-0.05|1), we will need to look at normal distribution\n",
    "    # with mean StatsByClass[0,0,0]=M00 and std StatsByClass[0,0,1]=S00\n",
    "    # In other words, area of std normal distribution b/w (sl-0.05-M00,sl+0.05-M00)/S00\n",
    "    # For simplicity, let us calculate these values anyway, then multiply or not depending on parameter's inclusion\n",
    "    \n",
    "    param = [sl, sw, pl, pw]\n",
    "    pS = numpy.zeros((4,3))\n",
    "    for i in range(4):\n",
    "        for k in range(3):\n",
    "            pS[i,k] = NormalProb(point=param[i], mean=StatsByClass[k,i,0], std=StatsByClass[k,i,1])\n",
    "    p = numpy.ones(3)\n",
    "    for i in range(4):\n",
    "        if param[i]>0:\n",
    "            p = p*pS[i]\n",
    "    return p/numpy.sum(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-623185e3e279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# still, after somehow populating pb, normalize:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mpb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;31m# break # placeholder until I manage to populate pb so that Normalize is not called on zero arrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdfb\u001b[0m \u001b[0;31m# for memory considerations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-623185e3e279>\u001b[0m in \u001b[0;36mNormalize\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sys\n",
    "import numpy\n",
    "\n",
    "def Normalize(a):\n",
    "    s = 0.\n",
    "    for i in a:\n",
    "        s = s + float(i)\n",
    "    return a / s\n",
    "\n",
    "df = pandas.read_csv('car_data.csv')\n",
    "\n",
    "# size = 1728 # = 4*4*4*3*3*3\n",
    "#   buying       v-high, high, med, low -> 0,1,2,3 each option 1/4\n",
    "#   maint        v-high, high, med, low -> 0,1,2,3 1/4\n",
    "#   doors        2, 3, 4, 5-more -> 0,1,2,3 1/4\n",
    "#   persons      2, 4, more -> 0,1,2\n",
    "#   lug_boot     small, med, big -> 0,1,2\n",
    "#   safety       low, med, high -> 0,1,2\n",
    "#   class:       unacc-1210-(70.023 %) / acc-384-(22.222 %) / good-69-( 3.993 %) / v-good-65-( 3.762 %) (a total of 1728)\n",
    "\n",
    "pb = numpy.zeros((4,4)) # first index is attribute option, second index is class\n",
    "pm = numpy.zeros((4,4)) # since no. of classes is always 4, 2nd index is always 4\n",
    "pd = numpy.zeros((4,4))\n",
    "pp = numpy.zeros((3,4))\n",
    "pl = numpy.zeros((3,4))\n",
    "ps = numpy.zeros((3,4))\n",
    "\n",
    "# OF IMPORTANCE:\n",
    "# Locating() and its series try to translate list values into proper indices\n",
    "# I am not particularly happy with this. There ought to be a better tool in the libraries I'm using (or not using),\n",
    "#     but my inexperience with them led me to this bulky 'solution'.\n",
    "def Locating(attribute, attValue, classValue):\n",
    "    aV, cV = 0,0\n",
    "    if classValue == 'acc':\n",
    "        cV = 1\n",
    "    elif classValue == 'good':\n",
    "        cV = 2\n",
    "    elif classValue == 'v-good':\n",
    "        cV = 3\n",
    "        \n",
    "    if attribute=='b' or attribute=='m':\n",
    "        if 'i' in attValue:\n",
    "            aV = 1\n",
    "        elif 'e' in attValue:\n",
    "            aV = 2\n",
    "        elif 'o' in attValue:\n",
    "            aV = 3\n",
    "        \n",
    "    if attribute=='d':\n",
    "        if attValue == 3 or attValue == '3':\n",
    "            aV = 1\n",
    "        elif attValue == 4 or attValue == '4':\n",
    "            aV = 2\n",
    "        elif attValue == '5-more':\n",
    "            aV = 3\n",
    "    \n",
    "    if attribute=='p':\n",
    "        if attValue == 4 or attValue == '4':\n",
    "            aV = 1\n",
    "        elif attValue == 'more':\n",
    "            aV = 2\n",
    "    \n",
    "    if attribute=='l' or attribute=='s':\n",
    "        if 'e' in attValue:\n",
    "            aV = 1\n",
    "        elif 'i' in attValue:\n",
    "            aV = 2\n",
    "        \n",
    "    return (aV, cV)\n",
    "\n",
    "def LocatingB(K):\n",
    "    index = Locating('b',K[0],K[1])\n",
    "    pb[index] = pb[index] +1\n",
    "def LocatingM(K):\n",
    "    index = Locating('m',K[0],K[1])\n",
    "    pm[index] = pm[index] +1\n",
    "def LocatingD(K):\n",
    "    index = Locating('d',K[0],K[1])\n",
    "    pd[index] = pd[index] +1\n",
    "def LocatingP(K):\n",
    "    index = Locating('p',K[0],K[1])\n",
    "    pp[index] = pp[index] +1\n",
    "def LocatingL(K):\n",
    "    index = Locating('l',K[0],K[1])\n",
    "    pl[index] = pl[index] +1\n",
    "def LocatingS(K):\n",
    "    index = Locating('s',K[0],K[1])\n",
    "    ps[index] = ps[index] +1\n",
    "        \n",
    "# OF IMPORTANCE:\n",
    "# dfb, ... dfs are tables with 2 columns: 1 attribute + 1 class.\n",
    "# pb, ... ps (called pA in general) are t*4 matrices: i'th row corresponds to p(class|Attribute=i) array.\n",
    "#     In that sense, we can also consider pA as arrays of arrays\n",
    "# To populate pA matrices, we need frequencies of classes for each specific Attribute instance.\n",
    "# To get frequencies, I opted to simply count instances of (Attribute AND Class),\n",
    "#     put those counts in their respective locations, and normalize the rows.\n",
    "# However, due to workings of numpy arrays, slicing 2-d matrices don't yield 1-d arrays, but apparently 1-d arrays of arrays.\n",
    "# This throws a wrench in my Normalize() function, which naively assumes input will be an array of numbers.\n",
    "\n",
    "\n",
    "dfb = df.filter(items=['buying', 'class'])\n",
    "# (I really don't want to loop over 1728 items... though on the second thought, how does frame do it? It probably just loops behind the curtains)\n",
    "dfb.apply(LocatingB, axis = 1)\n",
    "# still, after somehow populating pb, normalize:\n",
    "for i in range(4):\n",
    "    pb[:i] = Normalize(pb[:i])\n",
    "    # break # placeholder until I manage to populate pb so that Normalize is not called on zero arrays.\n",
    "del dfb # for memory considerations\n",
    "\n",
    "# this process needs to be done for all 6 attributes: buying, maint, doors, persons, lug_boot, safety\n",
    "# OF COURSE IT'D BE MUCH EASIER IF WE COULD DIRECTLY OBTAIN NUMBER OF ELEMENTS SATISFYING SOME CONDITIONS!\n",
    "# when all 6 attribute conditional probability matrices are filled, don't forget to  del df\n",
    "\n",
    "PClass = Normalize(numpy.array([1210, 384, 69, 65]))\n",
    "\n",
    "def ClassDetermination(buying,maint,doors,persons,lug_boot,safety): # attributes are given via numbers, not strings\n",
    "    p = numpy.zeros(4)\n",
    "    # FIRST COMMENT OF THE WORK: DETAILING OUR METHODOLOGY AND REASONING\n",
    "    # p1 = p(b,m,d,p,l,s|1)*p(1) = p(b|1)*p(m|1)*p(d|1)*p(p|1)*p(l|1)*p(s|1)*p(1) # \"Naive Bayes\" assumption\n",
    "    #     [LATER NOTE: (Here, p1 is shorthand for p(Class=1|Attributes = b,m,d,p,l,s))\n",
    "    #     And it is known that p1 is NOT EQUAL, but IN PROPORTION, to latter amount. That is why it's normalized in the end.\n",
    "    #         It's also known that, in our specific case, that denominator is simply 1728. However, since we're dealing with\n",
    "    #         an exercise, implementing in a general manner is thought to be better.]\n",
    "    # Of these 8 quantities, 1 is what we want, other 7 are what we'll use to compute it.\n",
    "    # Of these remaining 7, 1 (p(1)) is given by the system. we want to look at each 6 seperately to calculate them.\n",
    "    # Note that, in its most general case, p(b|1) will be an array of probabilities,\n",
    "    #     and that array will contain 4 elements since b has 4 options.\n",
    "    #     [LATER NOTE: this later became pb matrix, b'th row.]\n",
    "    # Once we have tool in place to compute p1, we'll be okay with p2, p3, p4 as well.\n",
    "    #     [LATER NOTE: that is to say, we will have pb matrix in its entirety.]\n",
    "    # Then we just return Normalize(numpy.array(p1, p2, p3, p4))\n",
    "    #     Each entry corresponds to prob of being unacc, acc, good and v-good.\n",
    "    for i in range(4):\n",
    "        p[i] = pb[buying,i]*pm[maint,i]*pd[doors,i]*pp[persons,i]*pl[lug_boot,i]*ps[safety,i]*PClass[i]\n",
    "    return Normalize(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.          0.          0.        ]\n",
      " [ 0.6         0.4         0.          0.        ]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 0.          0.          0.63636364  0.36363636]]\n",
      "[  1.   5.   3.  11.]\n",
      "20.0 [  1.   5.   3.  11.] [  4.   2.  10.   4.] [  4.   2.  10.   4.]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "# A suggestion: consider using dictionaries:\n",
    "keys = {'v-high':0, 'high':1, 'med':2, 'low':3 }\n",
    "classes = {'unacc':0, 'acc':1, 'good':2, 'v-good':3 }\n",
    "# ... and such.\n",
    "# Also, normalizing:\n",
    "T = numpy.zeros((4,4))\n",
    "T[0,0], T[1,1], T[2,2], T[3,3] = 1,2,3,4\n",
    "T[1,0], T[3,2] = 3,7\n",
    "# print(T)\n",
    "# print(T/numpy.sum(T))\n",
    "# print(T/numpy.sum(T,axis=1,keepdims=True))\n",
    "print(numpy.sum(T,axis=1,keepdims=False))\n",
    "# print(T/numpy.sum(T,axis=1,keepdims=False))\n",
    "#     when keepdims=False, it always returns a row, even when sum was over columns.\n",
    "print(numpy.sum(T),numpy.sum(T,axis=1),numpy.sum(T,axis=0),numpy.sum(T,axis=0,keepdims=False))\n",
    "\n",
    "# And a very simple thing:\n",
    "#     Python has ++: a += 1\n",
    "#\n",
    "#\n",
    "# Further, instead of df.filter(items=['Attribute','Class']), use zip(df['Attribute'],df['Class'])\n",
    "# This is good, because now we sensibly say u in zip(...), and then talk of u[0], u[1]\n",
    "# Furthermore, zip is a Python method, not numpy!\n",
    "#\n",
    "#\n",
    "# Next week take a look at Iris data set from scikit, which is, wait for it, continuous!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96495822,  0.03504178,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClassDetermination(buying=1, maint=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
