{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import time\n",
    "from IPython import display\n",
    "import numpy\n",
    "\n",
    "def AvSqEr(vector1, Matrix1, point1):\n",
    "    E = numpy.sum((vector1-Matrix1.dot(point1))**2)/len(vector1)\n",
    "    dE = -2.*Matrix1.T.dot((vector1-Matrix1.dot(point1)))/len(vector1)\n",
    "    return E, dE\n",
    "\n",
    "def VariableGradientDescent(varx, vary, trials):\n",
    "    N = len(varx)\n",
    "    # Design matrix\n",
    "    A = numpy.vstack((numpy.ones(N), varx, varx**2, varx**3)).T\n",
    "    \n",
    "    # Initial learning rate\n",
    "    alpha = 0.0000001\n",
    "    beta = 0.8\n",
    "    \n",
    "    # initial parameters\n",
    "    w = numpy.array([0., 0., 0., 0.])\n",
    "    p = numpy.array([0.,0.,0.,0.])\n",
    "\n",
    "    for epoch in range(trials):\n",
    "        E, dE = AvSqEr(vary, A, w)\n",
    "\n",
    "        if (epoch+1)%100 == 0: \n",
    "            print('Step', epoch,':', E, '//alpha:', alpha)\n",
    "\n",
    "        # Perfom one descent step\n",
    "        p = dE + beta*p\n",
    "        w1 = w - 1.1*alpha*p\n",
    "        if (AvSqEr(vary, A, w1)[0] < AvSqEr(vary, A, w-alpha*p)[0]):\n",
    "            alpha = 1.1*alpha\n",
    "            w = w1\n",
    "        else:\n",
    "            alpha = 0.5*alpha\n",
    "            w = w - alpha*p\n",
    "        \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 99 : 15.8200929123 //alpha: 2.144007704290544e-07\n",
      "Step 199 : 9.90472989931 //alpha: 1.112418106725845e-06\n",
      "Step 299 : 6.62939648087 //alpha: 1.192516495606257e-06\n",
      "Step 399 : 4.7364251171 //alpha: 5.81082853198495e-07\n",
      "Step 499 : 3.67100137834 //alpha: 6.229230570443521e-07\n",
      "Step 599 : 2.99296973835 //alpha: 6.677759167416544e-07\n",
      "Step 699 : 2.62660902027 //alpha: 3.2539016141676984e-07\n",
      "Step 799 : 2.38489776708 //alpha: 7.674029142756881e-07\n",
      "Step 899 : 2.25019171873 //alpha: 8.226588802510458e-07\n",
      "Step 999 : 2.15802542301 //alpha: 8.818934886306372e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.70082837493701e-07"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = numpy.array([8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68])\n",
    "x = numpy.array([10., 8., 13., 9., 11., 14., 6., 4., 12., 7., 5.])\n",
    "              \n",
    "VariableGradientDescent(x, y, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
